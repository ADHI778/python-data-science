{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the Pandas Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data into a data frame\n",
    "data = pd.read_csv('kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21613\n",
      "21\n",
      "[dtype('int64') dtype('O') dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of data points in the data set\n",
    "print(len(data))\n",
    "# Check the number of features in the data set\n",
    "print(len(data.columns))\n",
    "# Check the data types available in this dataset\n",
    "print(data.dtypes.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one both numerical and categorical columns in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Categorical Features\n",
    "We can get the categorical column list using the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select_dtypes(include=['O']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We only have one categorical columns which is the date column that we will ignore. If you are interested to fine tune this model further, then you can preprocess this column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17399</th>\n",
       "      <td>5153900080</td>\n",
       "      <td>20140714T000000</td>\n",
       "      <td>199000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1510</td>\n",
       "      <td>9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1510</td>\n",
       "      <td>0</td>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3331</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1180</td>\n",
       "      <td>7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701</th>\n",
       "      <td>1552800010</td>\n",
       "      <td>20150311T000000</td>\n",
       "      <td>352000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2980</td>\n",
       "      <td>9838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1710</td>\n",
       "      <td>1270</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>98030</td>\n",
       "      <td>47.3807</td>\n",
       "      <td>-122.222</td>\n",
       "      <td>2240</td>\n",
       "      <td>9838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17305</th>\n",
       "      <td>452002135</td>\n",
       "      <td>20150422T000000</td>\n",
       "      <td>1070000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2740</td>\n",
       "      <td>5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2740</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>98107</td>\n",
       "      <td>47.6740</td>\n",
       "      <td>-122.371</td>\n",
       "      <td>1660</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13795</th>\n",
       "      <td>9100000040</td>\n",
       "      <td>20140807T000000</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1710</td>\n",
       "      <td>4080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1130</td>\n",
       "      <td>580</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5563</td>\n",
       "      <td>-122.392</td>\n",
       "      <td>1200</td>\n",
       "      <td>4080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5446</th>\n",
       "      <td>7645900235</td>\n",
       "      <td>20140710T000000</td>\n",
       "      <td>880000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2640</td>\n",
       "      <td>3680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1760</td>\n",
       "      <td>880</td>\n",
       "      <td>1922</td>\n",
       "      <td>0</td>\n",
       "      <td>98126</td>\n",
       "      <td>47.5771</td>\n",
       "      <td>-122.380</td>\n",
       "      <td>1960</td>\n",
       "      <td>3680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date      price  bedrooms  bathrooms  \\\n",
       "17399  5153900080  20140714T000000   199000.0         3       1.00   \n",
       "5701   1552800010  20150311T000000   352000.0         5       2.75   \n",
       "17305   452002135  20150422T000000  1070000.0         4       2.50   \n",
       "13795  9100000040  20140807T000000   480000.0         3       1.75   \n",
       "5446   7645900235  20140710T000000   880000.0         6       2.50   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view     ...      grade  \\\n",
       "17399         1510      9100     1.0           0     0     ...          7   \n",
       "5701          2980      9838     1.0           0     0     ...          7   \n",
       "17305         2740      5000     2.0           0     0     ...          9   \n",
       "13795         1710      4080     1.0           0     0     ...          7   \n",
       "5446          2640      3680     2.0           0     0     ...          8   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "17399        1510              0      1966             0    98003  47.3331   \n",
       "5701         1710           1270      1968             0    98030  47.3807   \n",
       "17305        2740              0      2012             0    98107  47.6740   \n",
       "13795        1130            580      1979             0    98136  47.5563   \n",
       "5446         1760            880      1922             0    98126  47.5771   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "17399 -122.319           1180        7220  \n",
       "5701  -122.222           2240        9838  \n",
       "17305 -122.371           1660        5000  \n",
       "13795 -122.392           1200        4080  \n",
       "5446  -122.380           1960        3680  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view sample data\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we don not need the id column also. So drop the column while fitting the data in ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missing Value Columns List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the dimension of dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               21613\n",
       "date             21613\n",
       "price            21613\n",
       "bedrooms         21613\n",
       "bathrooms        21613\n",
       "sqft_living      21613\n",
       "sqft_lot         21613\n",
       "floors           21613\n",
       "waterfront       21613\n",
       "view             21613\n",
       "condition        21613\n",
       "grade            21613\n",
       "sqft_above       21613\n",
       "sqft_basement    21613\n",
       "yr_built         21613\n",
       "yr_renovated     21613\n",
       "zipcode          21613\n",
       "lat              21613\n",
       "long             21613\n",
       "sqft_living15    21613\n",
       "sqft_lot15       21613\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get record count for each variable\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains no missing value. So we can proceed further to make the machine learning model using the lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#separte x and y variable\n",
    "X_data = data[['sqft_living','grade', 'sqft_above', 'sqft_living15','bathrooms','view',\n",
    "                 'sqft_basement','lat','waterfront','yr_built','bedrooms']]\n",
    "X=X_data.values\n",
    "y = data.price.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17290, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get train and test dataset size\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17k records for training and 4k records for testing model efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. XGBoost Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import xgboost library\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try XGboost algorithm to see if we can get better results\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can give your custom values for the above parameters except objective. Why because we are doing the regression model, so the objective must be regression(more regression algorithms are available. Check documentation). To know more about parameters https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "Boosting type traditional Gradient Boosting Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert your data to lightgbm dataset format\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "d_valid = lgb.Dataset(X_test, label=y_test)\n",
    "valid_sets = [d_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 1.19068e+11\n",
      "[2]\tvalid_0's l2: 1.19027e+11\n",
      "[3]\tvalid_0's l2: 1.18987e+11\n",
      "[4]\tvalid_0's l2: 1.18947e+11\n",
      "[5]\tvalid_0's l2: 1.18907e+11\n",
      "[6]\tvalid_0's l2: 1.18866e+11\n",
      "[7]\tvalid_0's l2: 1.18826e+11\n",
      "[8]\tvalid_0's l2: 1.18786e+11\n",
      "[9]\tvalid_0's l2: 1.18746e+11\n",
      "[10]\tvalid_0's l2: 1.18706e+11\n",
      "[11]\tvalid_0's l2: 1.18666e+11\n",
      "[12]\tvalid_0's l2: 1.18625e+11\n",
      "[13]\tvalid_0's l2: 1.18585e+11\n",
      "[14]\tvalid_0's l2: 1.18545e+11\n",
      "[15]\tvalid_0's l2: 1.18505e+11\n",
      "[16]\tvalid_0's l2: 1.18465e+11\n",
      "[17]\tvalid_0's l2: 1.18425e+11\n",
      "[18]\tvalid_0's l2: 1.18385e+11\n",
      "[19]\tvalid_0's l2: 1.18345e+11\n",
      "[20]\tvalid_0's l2: 1.18305e+11\n",
      "[21]\tvalid_0's l2: 1.18265e+11\n",
      "[22]\tvalid_0's l2: 1.18225e+11\n",
      "[23]\tvalid_0's l2: 1.18186e+11\n",
      "[24]\tvalid_0's l2: 1.18146e+11\n",
      "[25]\tvalid_0's l2: 1.18106e+11\n",
      "[26]\tvalid_0's l2: 1.18066e+11\n",
      "[27]\tvalid_0's l2: 1.18026e+11\n",
      "[28]\tvalid_0's l2: 1.17986e+11\n",
      "[29]\tvalid_0's l2: 1.17948e+11\n",
      "[30]\tvalid_0's l2: 1.1791e+11\n",
      "[31]\tvalid_0's l2: 1.17871e+11\n",
      "[32]\tvalid_0's l2: 1.17833e+11\n",
      "[33]\tvalid_0's l2: 1.17795e+11\n",
      "[34]\tvalid_0's l2: 1.17756e+11\n",
      "[35]\tvalid_0's l2: 1.17718e+11\n",
      "[36]\tvalid_0's l2: 1.17679e+11\n",
      "[37]\tvalid_0's l2: 1.17641e+11\n",
      "[38]\tvalid_0's l2: 1.17603e+11\n",
      "[39]\tvalid_0's l2: 1.17565e+11\n",
      "[40]\tvalid_0's l2: 1.17526e+11\n",
      "[41]\tvalid_0's l2: 1.17488e+11\n",
      "[42]\tvalid_0's l2: 1.1745e+11\n",
      "[43]\tvalid_0's l2: 1.17412e+11\n",
      "[44]\tvalid_0's l2: 1.17374e+11\n",
      "[45]\tvalid_0's l2: 1.17336e+11\n",
      "[46]\tvalid_0's l2: 1.17297e+11\n",
      "[47]\tvalid_0's l2: 1.17259e+11\n",
      "[48]\tvalid_0's l2: 1.17221e+11\n",
      "[49]\tvalid_0's l2: 1.17183e+11\n",
      "[50]\tvalid_0's l2: 1.17145e+11\n",
      "[51]\tvalid_0's l2: 1.17107e+11\n",
      "[52]\tvalid_0's l2: 1.17069e+11\n",
      "[53]\tvalid_0's l2: 1.17031e+11\n",
      "[54]\tvalid_0's l2: 1.16993e+11\n",
      "[55]\tvalid_0's l2: 1.16955e+11\n",
      "[56]\tvalid_0's l2: 1.16917e+11\n",
      "[57]\tvalid_0's l2: 1.1688e+11\n",
      "[58]\tvalid_0's l2: 1.16843e+11\n",
      "[59]\tvalid_0's l2: 1.16807e+11\n",
      "[60]\tvalid_0's l2: 1.1677e+11\n",
      "[61]\tvalid_0's l2: 1.16733e+11\n",
      "[62]\tvalid_0's l2: 1.16696e+11\n",
      "[63]\tvalid_0's l2: 1.1666e+11\n",
      "[64]\tvalid_0's l2: 1.16623e+11\n",
      "[65]\tvalid_0's l2: 1.16586e+11\n",
      "[66]\tvalid_0's l2: 1.1655e+11\n",
      "[67]\tvalid_0's l2: 1.16513e+11\n",
      "[68]\tvalid_0's l2: 1.16477e+11\n",
      "[69]\tvalid_0's l2: 1.1644e+11\n",
      "[70]\tvalid_0's l2: 1.16403e+11\n",
      "[71]\tvalid_0's l2: 1.16367e+11\n",
      "[72]\tvalid_0's l2: 1.1633e+11\n",
      "[73]\tvalid_0's l2: 1.16294e+11\n",
      "[74]\tvalid_0's l2: 1.16257e+11\n",
      "[75]\tvalid_0's l2: 1.16221e+11\n",
      "[76]\tvalid_0's l2: 1.16185e+11\n",
      "[77]\tvalid_0's l2: 1.16148e+11\n",
      "[78]\tvalid_0's l2: 1.16112e+11\n",
      "[79]\tvalid_0's l2: 1.16075e+11\n",
      "[80]\tvalid_0's l2: 1.16039e+11\n",
      "[81]\tvalid_0's l2: 1.16003e+11\n",
      "[82]\tvalid_0's l2: 1.15966e+11\n",
      "[83]\tvalid_0's l2: 1.1593e+11\n",
      "[84]\tvalid_0's l2: 1.15893e+11\n",
      "[85]\tvalid_0's l2: 1.15857e+11\n",
      "[86]\tvalid_0's l2: 1.15821e+11\n",
      "[87]\tvalid_0's l2: 1.15784e+11\n",
      "[88]\tvalid_0's l2: 1.15748e+11\n",
      "[89]\tvalid_0's l2: 1.15712e+11\n",
      "[90]\tvalid_0's l2: 1.15675e+11\n",
      "[91]\tvalid_0's l2: 1.15639e+11\n",
      "[92]\tvalid_0's l2: 1.15603e+11\n",
      "[93]\tvalid_0's l2: 1.15567e+11\n",
      "[94]\tvalid_0's l2: 1.15531e+11\n",
      "[95]\tvalid_0's l2: 1.15494e+11\n",
      "[96]\tvalid_0's l2: 1.15458e+11\n",
      "[97]\tvalid_0's l2: 1.15422e+11\n",
      "[98]\tvalid_0's l2: 1.15385e+11\n",
      "[99]\tvalid_0's l2: 1.15349e+11\n",
      "[100]\tvalid_0's l2: 1.15313e+11\n"
     ]
    }
   ],
   "source": [
    "#pass data\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    'max_depth': 7, \n",
    "    'num_leaves':10,\n",
    "    'learning_rate': 0.5,\n",
    "    'verbose': 0\n",
    "}\n",
    "n_estimators = 100\n",
    "model = lgb.train(params=params, train_set=d_train, num_boost_round=n_estimators,\n",
    "                  valid_sets=valid_sets,verbose_eval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Computer Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 224653.524353\n",
      "Mean Squared Error: 115312905075.0\n",
      "Root Mean Squared Error: 339577.53912\n",
      "Explained Variance 0.0311840359791\n",
      "R Square : 0.0303669237836\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "# Evaluating the Algorithm\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Explained Variance',explained_variance_score(y_test,y_pred))\n",
    "print('R Square :', metrics.r2_score(y_test, y_pred))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 87852.5034367\n",
      "Mean Squared Error: 21712306616.1\n",
      "Root Mean Squared Error: 147350.964083\n",
      "Explained Variance 0.817427881063\n",
      "R Square : 0.817427454089\n"
     ]
    }
   ],
   "source": [
    "modelc=CatBoostRegressor(iterations=200,\n",
    "                            learning_rate=0.6,\n",
    "                            depth=8,\n",
    "                            loss_function='RMSE',\n",
    "                            eval_metric='RMSE',\n",
    "                            random_seed=99,\n",
    "                            od_type='Iter',\n",
    "                            od_wait=50)\n",
    "modelc.fit(X_train, y_train, eval_set=(X_test, y_test), use_best_model=True, verbose=False)\n",
    "y_pred = modelc.predict(X_test)\n",
    "# Evaluating the Algorithm\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Explained Variance',explained_variance_score(y_test,y_pred))\n",
    "print('R Square :', metrics.r2_score(y_test, y_pred))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 217080.187761\n",
      "Mean Squared Error: 111214696777.0\n",
      "Root Mean Squared Error: 333488.675635\n",
      "Explained Variance 0.0653091914419\n",
      "R Square : 0.0648275794798\n"
     ]
    }
   ],
   "source": [
    "modelg=lgb.LGBMRegressor(n_estimators=200)\n",
    "modelg.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
    "y_pred = modelg.predict(X_test)\n",
    "# Evaluating the Algorithm\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Explained Variance',explained_variance_score(y_test,y_pred))\n",
    "print('R Square :', metrics.r2_score(y_test, y_pred))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Applications/anaconda/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:104: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For early stopping, at least one dataset and eval metric is required for evaluation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-947ca4262333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m model = lgb.train(params=lgb_params, train_set=d_train, num_boost_round=n_estimators,\n\u001b[0;32m---> 16\u001b[0;31m                   valid_sets=valid_sets,verbose_eval=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/anaconda/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                         \u001b[0mbegin_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                                         \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_iteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                                         evaluation_result_list=evaluation_result_list))\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mearlyStopException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearlyStopException\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/anaconda/lib/python3.6/site-packages/lightgbm/callback.py\u001b[0m in \u001b[0;36mcallback\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;34m\"\"\"internal function\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcmp_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/anaconda/lib/python3.6/site-packages/lightgbm/callback.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;34m\"\"\"internal function\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For early stopping, at least one dataset and eval metric is required for evaluation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: For early stopping, at least one dataset and eval metric is required for evaluation"
     ]
    }
   ],
   "source": [
    "lgb_params = {}\n",
    "lgb_params['boost'] = 'gbdt'\n",
    "lgb_params['objective'] = 'regression_l2'\n",
    "lgb_params['num_leaves'] = 128\n",
    "lgb_params['sub_feature'] = 0.8 \n",
    "lgb_params['max_depth'] = 9\n",
    "lgb_params['feature_fraction'] = 0.7\n",
    "lgb_params['bagging_fraction'] = 0.7\n",
    "lgb_params['bagging_freq'] = 50\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['num_iterations'] = 1500\n",
    "lgb_params['early_stopping_round'] = 50\n",
    "lgb_params['verbose'] = 2\n",
    "\n",
    "model = lgb.train(params=lgb_params, train_set=d_train, num_boost_round=n_estimators,\n",
    "                  valid_sets=valid_sets,verbose_eval=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "# Evaluating the Algorithm\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Explained Variance',explained_variance_score(y_test,y_pred))\n",
    "print('R Square :', metrics.r2_score(y_test, y_pred))  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
